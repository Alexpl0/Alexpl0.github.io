<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Analizador de Emociones por Voz mediante IA</title>
    <link rel="stylesheet" href="presentation/src/css/styles.css">
</head>
<body>
    <div class="progress-bar">
        <div class="progress-fill" id="progressFill"></div>
    </div>
    
    <div class="slide-counter" id="slideCounter">1 / 15</div>

    <div class="presentation-container">
        <!-- Diapositiva 1: Título -->
        <div class="slide" data-slide="1">
            <h1>Analizador de Emociones por Voz mediante Inteligencia Artificial</h1>
            <div class="highlight-box">
                <h3>Propuesta de Proyecto para el Desarrollo de Asistente Psicológico Digital</h3>
                <p style="text-align: center; font-size: 1.2rem; margin-top: 20px;">
                    Democratizando el acceso a herramientas de evaluación psicológica preliminar
                </p>
            </div>
            
            <div class="team-info">
                <h3>Equipo de Desarrollo</h3>
                <p><strong>Alejandro Pérez</strong></p>
                <p><strong>Yusmany Rejopachi</strong></p>
                <p><strong>Jair Gutiérrez</strong></p>
            </div>
        </div>

        <!-- Diapositiva 2: Justificación -->
        <div class="slide hidden" data-slide="2">
            <h2>1. Justificación Técnica</h2>
            
            <div class="highlight-box">
                <h3>¿Por qué Audio para Reconocimiento Emocional?</h3>
                <p>La voz humana contiene información emocional rica y multidimensional que trasciende las palabras</p>
            </div>
            
            <div class="stats-grid">
                <div class="stat-item">
                    <h3>Características Prosódicas</h3>
                    <p>Pitch, intensidad, velocidad y ritmo revelan estados emocionales</p>
                </div>
                <div class="stat-item">
                    <h3>Patrones Espectrales</h3>
                    <p>Distribución de frecuencias única para cada emoción</p>
                </div>
                <div class="stat-item">
                    <h3>No Invasivo</h3>
                    <p>Captura natural sin intervención física o psicológica</p>
                </div>
            </div>
            
            <p><strong>¿Por qué Inteligencia Artificial?</strong></p>
            <ul>
                <li><strong>Procesamiento automático:</strong> Extracción de patrones complejos indetectables por análisis humano</li>
                <li><strong>Objetividad:</strong> Eliminación de sesgos subjetivos en la evaluación emocional</li>
                <li><strong>Escalabilidad:</strong> Análisis masivo de datos con consistencia temporal</li>
                <li><strong>Precisión espectral:</strong> Capacidad de detectar micropatrones en el dominio tiempo-frecuencia</li>
            </ul>
        </div>

        <!-- Diapositiva 3: Descripción del Problema -->
        <div class="slide hidden" data-slide="3">
            <h2>2. Descripción del Problema</h2>
            <div class="highlight-box">
                <h3>Problema Principal</h3>
                <p>Falta de herramientas automatizadas, objetivas y accesibles para la evaluación preliminar del estado emocional</p>
            </div>
            <h3>¿Qué pretendemos resolver?</h3>
            <ul>
                <li>Modelo capaz de analizar grabaciones de voz</li>
                <li>Identificar patrones emocionales: felicidad, tristeza, ira, miedo, sorpresa, disgusto, neutralidad</li>
                <li>Procesar audio en español mexicano</li>
                <li>Evaluación emocional confiable para contextos clínicos, educativos y de bienestar</li>
            </ul>
        </div>

        <!-- Diapositiva 4: Objetivos -->
        <div class="slide hidden" data-slide="4">
            <h2>3. Objetivo General</h2>
            <div class="highlight-box">
                <p>Desarrollar un modelo de inteligencia artificial capaz de reconocer y clasificar emociones humanas a partir del análisis acústico y prosódico del habla, con el propósito de crear una herramienta de evaluación emocional preliminar que pueda servir como base para un asistente psicológico digital.</p>
            </div>
        </div>

        <!-- Diapositiva 5: Objetivos Específicos -->
        <div class="slide hidden" data-slide="5">
            <h2>4. Objetivos Específicos</h2>
            <div class="methodology-step">
                <strong>1.</strong> Integrar y preprocesar múltiples conjuntos de datos de audio emocional
            </div>
            <div class="methodology-step">
                <strong>2.</strong> Extraer y analizar características acústicas relevantes del habla emocional
            </div>
            <div class="methodology-step">
                <strong>3.</strong> Diseñar, entrenar y optimizar modelos especializados de aprendizaje automático
            </div>
            <div class="methodology-step">
                <strong>4.</strong> Evaluar el rendimiento utilizando métricas estándar de clasificación
            </div>
            <div class="methodology-step">
                <strong>5.</strong> Implementar técnicas de reducción de dimensionalidad y visualización
            </div>
        </div>

        <!-- Diapositiva 6: Metodología con Diagrama -->
        <div class="slide hidden" data-slide="6">
            <h2>5. Metodología</h2>
            <p>Enfoque de desarrollo iterativo y adaptativo:</p>
            
            <!-- Diagrama de flujo de la metodología -->
            <div class="methodology-diagram">
                <div class="methodology-box start">
                    <h4>Adquisición de Datos</h4>
                    <p>Recolección y consolidación de datasets</p>
                </div>
                <div class="arrow">↓</div>
                
                <div class="methodology-box">
                    <h4>Análisis Exploratorio</h4>
                    <p>Comprensión profunda de los datos</p>
                </div>
                <div class="arrow">↓</div>
                
                <div class="methodology-box">
                    <h4>Preprocesamiento</h4>
                    <p>Limpieza y preparación de señales</p>
                </div>
                <div class="arrow">↓</div>
                
                <div class="methodology-box">
                    <h4>Extracción de Características</h4>
                    <p>Identificación de patrones discriminativos</p>
                </div>
                <div class="arrow">↓</div>
                
                <div class="methodology-box">
                    <h4>Entrenamiento del Modelo</h4>
                    <p>Desarrollo y optimización</p>
                </div>
                <div class="arrow">↓</div>
                
                <div class="methodology-box">
                    <h4>Evaluación</h4>
                    <p>Validación y mejora continua</p>
                </div>
                
                <!-- Flecha de retroalimentación -->
                <div class="feedback-arrow">
                    <p>Retroalimentación e iteración según resultados</p>
                </div>
            </div>
        </div>

        <!-- Diapositiva 7: Conjuntos de Datos -->
        <div class="slide hidden" data-slide="7">
            <h2>6. Adquisición de Conjuntos de Datos</h2>
            <div class="dataset-card">
                <h3>Conjunto 1: Base de Datos de Habla Emocional Mexicana (MESD)</h3>
                <ul>
                    <li><strong>Cantidad:</strong> 864 grabaciones de audio</li>
                    <li><strong>Características:</strong> Español mexicano, 6 emociones + neutralidad</li>
                    <li><strong>Utilidad:</strong> Adaptación específica al habla mexicana</li>
                </ul>
            </div>
            <div class="dataset-card">
                <h3>Conjunto 2: Audio de Habla Emocional RAVDESS</h3>
                <ul>
                    <li><strong>Cantidad:</strong> 1,440 grabaciones vocales</li>
                    <li><strong>Características:</strong> Calidad profesional, 24 actores</li>
                    <li><strong>Utilidad:</strong> Benchmarks robustos de rendimiento</li>
                </ul>
            </div>
            <div class="dataset-card">
                <h3>Conjunto 3: Reconocimiento de Emociones en Habla (EN)</h3>
                <ul>
                    <li><strong>Cantidad:</strong> 2,800 muestras de audio</li>
                    <li><strong>Características:</strong> Situaciones naturales y espontáneas</li>
                    <li><strong>Utilidad:</strong> Generalización a uso del mundo real</li>
                </ul>
            </div>
        </div>

        <!-- Diapositiva 8: Análisis Exploratorio -->
        <div class="slide hidden" data-slide="8">
            <h2>7. Análisis Exploratorio de Datos (EDA)</h2>
            <h3>Preguntas principales de investigación:</h3>
            <ul>
                <li>¿Existen diferencias espectrales consistentes entre estados emocionales?</li>
                <li>¿Cómo varían las características prosódicas entre emociones?</li>
                <li>¿Qué nivel de variabilidad existe dentro de cada categoría?</li>
                <li>¿Hay sesgos demográficos o técnicos en los conjuntos de datos?</li>
            </ul>
            <h3>Visualizaciones Seleccionadas:</h3>
            <div class="methodology-step">
                <strong>1.</strong> Histogramas de Características Prosódicas
            </div>
            <div class="methodology-step">
                <strong>2.</strong> Mapas de Calor de Correlación Espectral
            </div>
            <div class="methodology-step">
                <strong>3.</strong> Gráficos de Dispersión de Componentes Principales
            </div>
        </div>

        <!-- Diapositiva 9: Visualización de Gráficas de Análisis Exploratorio -->
        <div class="slide hidden" data-slide="9">
            <h2>8. Visualización de Características Acústicas</h2>
            <div class="graph-section">
                <h3>1. Distribución del Pitch Fundamental por Emoción</h3>
                <img src="presentation/src/assets/images/histograma_pitch_por_emocion.png" alt="Histograma Pitch por Emoción" style="max-width: 90%; border: 1px solid #ccc;">
                <p>
                    <strong>¿Qué muestra?</strong> La distribución del pitch fundamental (frecuencia de la voz) para cada emoción. Se observa que emociones como alegría y enojo tienden a tener un pitch más alto, mientras que la tristeza se concentra en valores bajos. Esto ayuda a diferenciar emociones a partir de la voz.
                </p>
            </div>
            <div class="graph-section">
                <h3>2. Matriz de Correlación entre MFCC y Emociones</h3>
                <img src="presentation/src/assets/images/heatmap_correlacion_mfcc_emocion.png" alt="Mapa de calor MFCC-Emoción" style="max-width: 90%; border: 1px solid #ccc;">
                <p>
                    <strong>¿Qué muestra?</strong> El grado de correlación entre los coeficientes MFCC (características espectrales de la voz) y las emociones. Los colores indican si un MFCC está más asociado a una emoción específica, guiando la selección de características para el modelo.
                </p>
            </div>
            <div class="graph-section">
                <h3>3. Proyección PCA de Características Acústicas</h3>
                <img src="presentation/src/assets/images/pca_emociones.png" alt="PCA Emociones" style="max-width: 90%; border: 1px solid #ccc;">
                <p>
                    <strong>¿Qué muestra?</strong> Una reducción de dimensionalidad (PCA) de las características acústicas, donde cada punto es una grabación y el color indica la emoción. Permite visualizar qué tan separables son las emociones en el espacio de características.
                </p>
            </div>
        </div>

        <!-- Diapositiva 10: Preprocesamiento con Diagramas -->
        <div class="slide hidden" data-slide="10">
            <h2>9. Preprocesamiento de Datos</h2>
            
            <div class="preprocessing-grid">
                <div class="preprocessing-item">
                    <h4>Normalización de Audio</h4>
                    <div class="before-after">
                        <div class="before">
                            <p><strong>Antes:</strong></p>
                            <div class="audio-visual noisy">Diferentes formatos y calidades</div>
                        </div>
                        <div class="arrow">→</div>
                        <div class="after">
                            <p><strong>Después:</strong></p>
                            <div class="audio-visual clean">16 kHz, 16 bits estándar</div>
                        </div>
                    </div>
                </div>

                <div class="preprocessing-item">
                    <h4>Eliminación de Datos Corruptos</h4>
                    <div class="before-after">
                        <div class="before">
                            <p><strong>Antes:</strong></p>
                            <div class="audio-visual corrupted">Archivos dañados o muy cortos</div>
                        </div>
                        <div class="arrow">→</div>
                        <div class="after">
                            <p><strong>Después:</strong></p>
                            <div class="audio-visual validated">Solo archivos válidos >1s</div>
                        </div>
                    </div>
                </div>

                <div class="preprocessing-item">
                    <h4>Filtrado de Ruido</h4>
                    <div class="before-after">
                        <div class="before">
                            <p><strong>Antes:</strong></p>
                            <div class="audio-visual noisy">Ruido de fondo presente</div>
                        </div>
                        <div class="arrow">→</div>
                        <div class="after">
                            <p><strong>Después:</strong></p>
                            <div class="audio-visual filtered">Señal limpia y clara</div>
                        </div>
                    </div>
                </div>

                <div class="preprocessing-item">
                    <h4>Segmentación Temporal</h4>
                    <div class="before-after">
                        <div class="before">
                            <p><strong>Antes:</strong></p>
                            <div class="audio-visual long">Grabaciones de duración variable</div>
                        </div>
                        <div class="arrow">→</div>
                        <div class="after">
                            <p><strong>Después:</strong></p>
                            <div class="audio-visual segmented">Ventanas de 2-4s con solapamiento</div>
                        </div>
                    </div>
                </div>

                <div class="preprocessing-item">
                    <h4>Balanceo de Clases</h4>
                    <div class="before-after">
                        <div class="before">
                            <p><strong>Antes:</strong></p>
                            <div class="class-distribution unbalanced">
                                <div class="class-bar" style="height: 60%;" data-label="Felicidad"></div>
                                <div class="class-bar" style="height: 30%;" data-label="Tristeza"></div>
                                <div class="class-bar" style="height: 80%;" data-label="Ira"></div>
                                <div class="class-bar" style="height: 20%;" data-label="Miedo"></div>
                            </div>
                        </div>
                        <div class="arrow">→</div>
                        <div class="after">
                            <p><strong>Después:</strong></p>
                            <div class="class-distribution balanced">
                                <div class="class-bar" style="height: 50%;" data-label="Felicidad"></div>
                                <div class="class-bar" style="height: 50%;" data-label="Tristeza"></div>
                                <div class="class-bar" style="height: 50%;" data-label="Ira"></div>
                                <div class="class-bar" style="height: 50%;" data-label="Miedo"></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Diapositiva 11: Reducción de Dimensionalidad -->
        <div class="slide hidden" data-slide="11">
            <h2>9. Reducción de Dimensionalidad</h2>
            <h3>¿Por qué es útil?</h3>
            <ul>
                <li>Mitigar la "maldición de la dimensionalidad"</li>
                <li>Mejorar la eficiencia computacional</li>
                <li>Reducir el riesgo de sobreajuste</li>
                <li>Facilitar la visualización e interpretación</li>
            </ul>
            <h3>Técnicas a aplicar:</h3>
            <div class="advantages-disadvantages">
                <div class="advantages">
                    <h4>Análisis de Componentes Principales (PCA)</h4>
                    <p>Identificar direcciones de máxima varianza</p>
                    <h4>Análisis Discriminante Lineal (LDA)</h4>
                    <p>Maximizar separación entre clases emocionales</p>
                </div>
                <div class="disadvantages">
                    <h4>t-SNE</h4>
                    <p>Visualización de estructuras complejas</p>
                    <h4>UMAP</h4>
                    <p>Preservar estructura local y global</p>
                </div>
            </div>
        </div>

        <!-- Diapositiva 12: Fundamento Teórico con CNN -->
        <div class="slide hidden" data-slide="12">
            <h2>10. Fundamento Teórico</h2>
            <h3>Algoritmo Principal: Redes Neuronales Convolucionales (CNN)</h3>
            <div class="highlight-box">
                <p>Las CNN procesan espectrogramas de audio como imágenes bidimensionales, detectando patrones espacio-temporales característicos de diferentes estados emocionales.</p>
            </div>

            <h3>Justificación de uso:</h3>
            <ul>
                <li>Los patrones emocionales se manifiestan como estructuras espacio-temporales</li>
                <li>Casos de éxito documentados: Zhao et al. (2019) - 85% de precisión</li>
                <li>Invariancia traslacional para diferentes tiempos de expresión</li>
                <li>Capacidad de generalización jerárquica</li>
            </ul>

            <h3>Ventajas y Limitaciones:</h3>
            <div class="advantages-disadvantages">
                <div class="advantages">
                    <h4>Ventajas</h4>
                    <ul>
                        <li>Extracción automática de características</li>
                        <li>Robustez ante variaciones locales</li>
                        <li>Escalabilidad computacional</li>
                        <li>Interpretabilidad parcial</li>
                    </ul>
                </div>
                <div class="disadvantages">
                    <h4>Limitaciones</h4>
                    <ul>
                        <li>Dependencia de grandes volúmenes de datos</li>
                        <li>Sensibilidad a la calidad del preprocesamiento</li>
                        <li>Interpretabilidad limitada</li>
                        <li>Posible sesgo hacia características específicas</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Diapositiva 13: Análisis Espectral Detallado -->
        <div class="slide hidden" data-slide="13">
            <h2>11. Análisis Espectral: Procesamiento de Datos por CNN</h2>
            <div class="highlight-box">
                <p>Ejemplo de cómo las CNN procesan las diferentes representaciones espectrales del audio emocional</p>
            </div>
            
            <!-- Imagen de espectrograma con análisis detallado -->
            <div class="spectrogram-analysis">
                <img src="presentation/src/assets/images/MESD_1_Neutral_F_A_mecanico.png" alt="Análisis Espectral Completo - MESD Neutral" style="max-width: 100%; border-radius: 15px; box-shadow: 0 10px 25px rgba(13, 24, 38, 0.3);">
                
                <div class="analysis-grid">
                    <div class="analysis-item">
                        <h4>🌊 Forma de Onda</h4>
                        <p><strong>Superior izquierda:</strong> Representa la amplitud de la señal de audio a lo largo del tiempo. Las variaciones muestran la intensidad vocal y patrones de entonación característicos del habla emocional neutra.</p>
                    </div>
                    
                    <div class="analysis-item">
                        <h4>📊 Espectrograma Lineal</h4>
                        <p><strong>Superior derecha:</strong> Visualización tiempo-frecuencia que muestra cómo se distribuye la energía espectral. Los colores cálidos indican mayor energía en esas frecuencias específicas durante momentos particulares.</p>
                    </div>
                    
                    <div class="analysis-item">
                        <h4>🎵 Espectrograma Mel</h4>
                        <p><strong>Inferior izquierda:</strong> Representación perceptualmente relevante que imita cómo el oído humano procesa las frecuencias. Las bandas Mel capturan características espectrales cruciales para el reconocimiento emocional.</p>
                    </div>
                    
                    <div class="analysis-item">
                        <h4>🎹 Cromograma</h4>
                        <p><strong>Inferior derecha:</strong> Análisis de las clases de pitch (Do, Re, Mi...) presentes en la voz. Revela patrones tonales que pueden ser distintivos para diferentes estados emocionales.</p>
                    </div>
                </div>
            </div>

            <p><strong>¿Cómo procesan esto las CNN?</strong> Cada representación proporciona información complementaria que los filtros convolucionales capturan automáticamente, creando mapas de características que identifican patrones emocionales únicos.</p>
        </div>

        <!-- Diapositiva 14: Arquitectura de la Red Neuronal -->
        <div class="slide hidden" data-slide="14">
            <h2>12. Arquitectura de la Red Neuronal</h2>
            
            <div class="neural-architecture">
                <div class="layer-box input">
                    <h4>Entrada</h4>
                    <p>Espectrograma (128 x 128 x 1)</p>
                    <div class="layer-description">
                        <strong>Proceso:</strong> Conversión de audio a representación visual
                    </div>
                </div>
                
                <div class="arrow">↓</div>
                
                <div class="layer-box conv">
                    <h4>Capa Convolucional 1</h4>
                    <p>32 filtros, kernel 3x3, ReLU</p>
                    <div class="layer-description">
                        <strong>Proceso:</strong> Detección de patrones locales básicos
                    </div>
                </div>
                
                <div class="arrow">↓</div>
                
                <div class="layer-box pool">
                    <h4>MaxPooling 1</h4>
                    <p>Pool size 2x2</p>
                    <div class="layer-description">
                        <strong>Proceso:</strong> Reducción dimensional y extracción de características dominantes
                    </div>
                </div>
                
                <div class="arrow">↓</div>
                
                <div class="layer-box conv">
                    <h4>Capa Convolucional 2</h4>
                    <p>64 filtros, kernel 3x3, ReLU</p>
                    <div class="layer-description">
                        <strong>Proceso:</strong> Detección de patrones más complejos
                    </div>
                </div>
                
                <div class="arrow">↓</div>
                
                <div class="layer-box dense">
                    <h4>Capa Densa</h4>
                    <p>128 neuronas, ReLU, Dropout 0.3</p>
                    <div class="layer-description">
                        <strong>Proceso:</strong> Combinación de características para decisión final
                    </div>
                </div>
                
                <div class="arrow">↓</div>
                
                <div class="layer-box output">
                    <h4>Salida</h4>
                    <p>7 neuronas, Softmax</p>
                    <div class="layer-description">
                        <strong>Proceso:</strong> Clasificación probabilística de emociones
                    </div>
                </div>
            </div>
        </div>

        <!-- Diapositiva 15: Recursos -->
        <div class="slide hidden" data-slide="15">
            <h2>13. Recursos</h2>
            <div class="dataset-card">
                <h3>Lenguaje y Frameworks</h3>
                <ul>
                    <li><strong>Python 3.8+:</strong> Lenguaje principal</li>
                    <li><strong>TensorFlow 2.x/Keras:</strong> Desarrollo de CNN</li>
                    <li><strong>Librosa:</strong> Procesamiento especializado de audio</li>
                    <li><strong>Scikit-learn:</strong> Preprocesamiento y métricas</li>
                </ul>
            </div>
            <div class="dataset-card">
                <h3>Hardware y Plataformas</h3>
                <ul>
                    <li><strong>Google Colab Pro:</strong> GPUs Tesla T4/V100</li>
                    <li><strong>Jupyter Notebook:</strong> Desarrollo local</li>
                    <li><strong>GitHub:</strong> Control de versiones</li>
                    <li><strong>Weights & Biases:</strong> Monitoreo de entrenamiento</li>
                </ul>
            </div>
        </div>

        <!-- Diapositiva 16: Alcance del Proyecto -->
        <div class="slide hidden" data-slide="16">
            <h2>14. Alcance del Proyecto</h2>
            <div class="advantages-disadvantages">
                <div class="advantages">
                    <h3>Incluido en el Proyecto</h3>
                    <ul>
                        <li>Modelo completo de reconocimiento de 7 emociones</li>
                        <li>Pipeline completo de carga a evaluación</li>
                        <li>Procesamiento de audio WAV (1-10 segundos)</li>
                        <li>API de clasificación con puntuaciones de confianza</li>
                        <li>Métricas completas de rendimiento</li>
                    </ul>
                </div>
                <div class="disadvantages">
                    <h3>Limitaciones y Exclusiones</h3>
                    <ul>
                        <li>Solo análisis de audio (sin video/texto)</li>
                        <li>Sin aplicación web completa</li>
                        <li>Sin procesamiento en tiempo real inicial</li>
                        <li>Sin evaluación clínica formal</li>
                        <li>Sin diagnóstico médico o recomendaciones</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Diapositiva 17: Despedida -->
        <div class="slide hidden farewell-slide" data-slide="17">
            <h1 class="farewell-title">¡Gracias!</h1>
            <p class="farewell-message">
                Esperamos que esta propuesta haya demostrado el potencial de la inteligencia artificial<br>
                para democratizar el acceso a herramientas de evaluación emocional.
            </p>
            
            <div class="highlight-box">
                <h3>🤔 ¿Preguntas o Comentarios?</h3>
                <p style="font-size: 1.2rem; margin-top: 15px;">
                    Estamos aquí para resolver cualquier duda sobre el proyecto<br>
                    y discutir las posibilidades de implementación.
                </p>
            </div>

            <div class="contact-info">
                <h3>Equipo de Desarrollo</h3>
                <p><strong>📧 Contacto disponible para colaboraciones futuras</strong></p>
                <p>Alejandro Pérez • Yusmany Rejopachi • Jair Gutiérrez</p>
            </div>
        </div>
    </div>

    <div class="navigation">
        <button class="nav-btn" onclick="previousSlide()">← Anterior</button>
        <button class="nav-btn" onclick="nextSlide()">Siguiente →</button>
    </div>

    <script src="presentation/src/js/script.js"></script>
</body>
</html>