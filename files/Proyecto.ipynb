{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddbb5963",
   "metadata": {},
   "source": [
    "# Analizador de Emociones por Voz mediante Inteligencia Artificial\n",
    "\n",
    "## 1. Instalación e Importación de Librerías\n",
    "\n",
    "```python\n",
    "# Instalación de librerías necesarias\n",
    "!pip install librosa soundfile numpy pandas scikit-learn tensorflow matplotlib seaborn\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Conv1D, MaxPooling1D, Flatten\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "```\n",
    "\n",
    "## 2. Funciones para Carga y Preprocesamiento de Audio\n",
    "\n",
    "```python\n",
    "def load_audio_file(file_path, sample_rate=22050):\n",
    "    \"\"\"\n",
    "    Carga un archivo de audio y lo convierte al sample rate especificado\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=sample_rate)\n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando archivo {file_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def preprocess_audio(audio, sr=22050, duration=3.0):\n",
    "    \"\"\"\n",
    "    Preprocesa el audio: normalización y ajuste de duración\n",
    "    \"\"\"\n",
    "    # Normalizar audio\n",
    "    audio = librosa.util.normalize(audio)\n",
    "    \n",
    "    # Ajustar duración (padding o truncado)\n",
    "    target_length = int(sr * duration)\n",
    "    if len(audio) > target_length:\n",
    "        audio = audio[:target_length]\n",
    "    else:\n",
    "        audio = np.pad(audio, (0, target_length - len(audio)), mode='constant')\n",
    "    \n",
    "    return audio\n",
    "```\n",
    "\n",
    "## 3. Extracción de Características de Audio\n",
    "\n",
    "```python\n",
    "def extract_features(audio, sr=22050):\n",
    "    \"\"\"\n",
    "    Extrae características relevantes del audio para análisis de emociones\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # 1. Características espectrales\n",
    "    # MFCC (Mel-frequency cepstral coefficients)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    features['mfcc_mean'] = np.mean(mfccs, axis=1)\n",
    "    features['mfcc_std'] = np.std(mfccs, axis=1)\n",
    "    \n",
    "    # Espectrograma Mel\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "    features['mel_mean'] = np.mean(mel_spec, axis=1)\n",
    "    features['mel_std'] = np.std(mel_spec, axis=1)\n",
    "    \n",
    "    # 2. Características de tono\n",
    "    # Frecuencia fundamental (F0)\n",
    "    pitches, magnitudes = librosa.piptrack(y=audio, sr=sr)\n",
    "    pitch_values = []\n",
    "    for t in range(pitches.shape[1]):\n",
    "        index = magnitudes[:, t].argmax()\n",
    "        pitch = pitches[index, t]\n",
    "        if pitch > 0:\n",
    "            pitch_values.append(pitch)\n",
    "    \n",
    "    if pitch_values:\n",
    "        features['pitch_mean'] = np.mean(pitch_values)\n",
    "        features['pitch_std'] = np.std(pitch_values)\n",
    "        features['pitch_min'] = np.min(pitch_values)\n",
    "        features['pitch_max'] = np.max(pitch_values)\n",
    "    else:\n",
    "        features['pitch_mean'] = features['pitch_std'] = 0\n",
    "        features['pitch_min'] = features['pitch_max'] = 0\n",
    "    \n",
    "    # 3. Características de energía\n",
    "    # RMS (Root Mean Square) - energía\n",
    "    rms = librosa.feature.rms(y=audio)\n",
    "    features['rms_mean'] = np.mean(rms)\n",
    "    features['rms_std'] = np.std(rms)\n",
    "    \n",
    "    # Zero Crossing Rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(audio)\n",
    "    features['zcr_mean'] = np.mean(zcr)\n",
    "    features['zcr_std'] = np.std(zcr)\n",
    "    \n",
    "    # 4. Características temporales\n",
    "    # Centroide espectral\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)\n",
    "    features['spectral_centroid_mean'] = np.mean(spectral_centroids)\n",
    "    features['spectral_centroid_std'] = np.std(spectral_centroids)\n",
    "    \n",
    "    # Rolloff espectral\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n",
    "    features['spectral_rolloff_mean'] = np.mean(spectral_rolloff)\n",
    "    features['spectral_rolloff_std'] = np.std(spectral_rolloff)\n",
    "    \n",
    "    # Convertir a array plano\n",
    "    feature_vector = []\n",
    "    for key in sorted(features.keys()):\n",
    "        if isinstance(features[key], np.ndarray):\n",
    "            feature_vector.extend(features[key])\n",
    "        else:\n",
    "            feature_vector.append(features[key])\n",
    "    \n",
    "    return np.array(feature_vector)\n",
    "```\n",
    "\n",
    "## 4. Preparación del Dataset\n",
    "\n",
    "```python\n",
    "def prepare_dataset(audio_directory, emotions_mapping):\n",
    "    \"\"\"\n",
    "    Prepara el dataset extrayendo características de todos los archivos de audio\n",
    "    \n",
    "    audio_directory: directorio con archivos de audio organizados por emoción\n",
    "    emotions_mapping: diccionario que mapea nombres de carpetas a emociones\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    emotions_list = []\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    for emotion_folder in os.listdir(audio_directory):\n",
    "        if emotion_folder in emotions_mapping:\n",
    "            emotion_path = os.path.join(audio_directory, emotion_folder)\n",
    "            emotion_label = emotions_mapping[emotion_folder]\n",
    "            \n",
    "            for audio_file in os.listdir(emotion_path):\n",
    "                if audio_file.endswith(('.wav', '.mp3', '.m4a')):\n",
    "                    file_path = os.path.join(emotion_path, audio_file)\n",
    "                    \n",
    "                    # Cargar y preprocesar audio\n",
    "                    audio, sr = load_audio_file(file_path)\n",
    "                    if audio is not None:\n",
    "                        audio = preprocess_audio(audio, sr)\n",
    "                        \n",
    "                        # Extraer características\n",
    "                        features = extract_features(audio, sr)\n",
    "                        \n",
    "                        features_list.append(features)\n",
    "                        emotions_list.append(emotion_label)\n",
    "    \n",
    "    return np.array(features_list), np.array(emotions_list)\n",
    "\n",
    "# Ejemplo de mapeo de emociones\n",
    "emotions_mapping = {\n",
    "    'happy': 'Felicidad',\n",
    "    'sad': 'Tristeza',\n",
    "    'angry': 'Enojo',\n",
    "    'fear': 'Miedo',\n",
    "    'neutral': 'Neutral',\n",
    "    'surprise': 'Sorpresa',\n",
    "    'disgust': 'Disgusto'\n",
    "}\n",
    "```\n",
    "\n",
    "## 5. Exploración y Visualización de Datos\n",
    "\n",
    "```python\n",
    "def visualize_audio_features(features_df, emotions):\n",
    "    \"\"\"\n",
    "    Visualiza las características extraídas del audio\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Distribución de emociones\n",
    "    plt.subplot(2, 3, 1)\n",
    "    emotion_counts = pd.Series(emotions).value_counts()\n",
    "    plt.pie(emotion_counts.values, labels=emotion_counts.index, autopct='%1.1f%%')\n",
    "    plt.title('Distribución de Emociones')\n",
    "    \n",
    "    # Características MFCC promedio por emoción\n",
    "    plt.subplot(2, 3, 2)\n",
    "    mfcc_cols = [col for col in features_df.columns if 'mfcc_mean' in col]\n",
    "    mfcc_data = features_df[mfcc_cols].values\n",
    "    \n",
    "    for i, emotion in enumerate(np.unique(emotions)):\n",
    "        emotion_mask = emotions == emotion\n",
    "        plt.plot(np.mean(mfcc_data[emotion_mask], axis=0), label=emotion)\n",
    "    \n",
    "    plt.xlabel('Coeficientes MFCC')\n",
    "    plt.ylabel('Valor Promedio')\n",
    "    plt.title('MFCC Promedio por Emoción')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Pitch promedio por emoción\n",
    "    plt.subplot(2, 3, 3)\n",
    "    pitch_data = []\n",
    "    emotion_labels = []\n",
    "    \n",
    "    for emotion in np.unique(emotions):\n",
    "        emotion_mask = emotions == emotion\n",
    "        pitch_values = features_df.loc[emotion_mask, 'pitch_mean'].values\n",
    "        pitch_data.extend(pitch_values)\n",
    "        emotion_labels.extend([emotion] * len(pitch_values))\n",
    "    \n",
    "    sns.boxplot(x=emotion_labels, y=pitch_data)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Distribución de Pitch por Emoción')\n",
    "    \n",
    "    # Energía (RMS) por emoción\n",
    "    plt.subplot(2, 3, 4)\n",
    "    rms_data = []\n",
    "    emotion_labels = []\n",
    "    \n",
    "    for emotion in np.unique(emotions):\n",
    "        emotion_mask = emotions == emotion\n",
    "        rms_values = features_df.loc[emotion_mask, 'rms_mean'].values\n",
    "        rms_data.extend(rms_values)\n",
    "        emotion_labels.extend([emotion] * len(rms_values))\n",
    "    \n",
    "    sns.boxplot(x=emotion_labels, y=rms_data)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Distribución de Energía (RMS) por Emoción')\n",
    "    \n",
    "    # Zero Crossing Rate por emoción\n",
    "    plt.subplot(2, 3, 5)\n",
    "    zcr_data = []\n",
    "    emotion_labels = []\n",
    "    \n",
    "    for emotion in np.unique(emotions):\n",
    "        emotion_mask = emotions == emotion\n",
    "        zcr_values = features_df.loc[emotion_mask, 'zcr_mean'].values\n",
    "        zcr_data.extend(zcr_values)\n",
    "        emotion_labels.extend([emotion] * len(zcr_values))\n",
    "    \n",
    "    sns.boxplot(x=emotion_labels, y=zcr_data)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Zero Crossing Rate por Emoción')\n",
    "    \n",
    "    # Matriz de correlación\n",
    "    plt.subplot(2, 3, 6)\n",
    "    correlation_matrix = features_df.corr()\n",
    "    sns.heatmap(correlation_matrix.iloc[:10, :10], annot=True, cmap='coolwarm')\n",
    "    plt.title('Matriz de Correlación (Primeras 10 características)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "## 6. Modelos de Machine Learning\n",
    "\n",
    "```python\n",
    "class EmotionClassifier:\n",
    "    def __init__(self, model_type='neural_network'):\n",
    "        self.model_type = model_type\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "    def create_neural_network(self, input_shape, num_classes):\n",
    "        \"\"\"\n",
    "        Crea una red neuronal profunda para clasificación de emociones\n",
    "        \"\"\"\n",
    "        model = Sequential([\n",
    "            Dense(512, activation='relu', input_shape=(input_shape,)),\n",
    "            Dropout(0.3),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def create_cnn_model(self, input_shape, num_classes):\n",
    "        \"\"\"\n",
    "        Crea un modelo CNN para análisis de características temporales\n",
    "        \"\"\"\n",
    "        model = Sequential([\n",
    "            tf.keras.layers.Reshape((input_shape, 1), input_shape=(input_shape,)),\n",
    "            Conv1D(64, 3, activation='relu'),\n",
    "            MaxPooling1D(2),\n",
    "            Conv1D(128, 3, activation='relu'),\n",
    "            MaxPooling1D(2),\n",
    "            Conv1D(256, 3, activation='relu'),\n",
    "            MaxPooling1D(2),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs=100, batch_size=32):\n",
    "        \"\"\"\n",
    "        Entrena el modelo de clasificación de emociones\n",
    "        \"\"\"\n",
    "        # Normalizar características\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_val_scaled = self.scaler.transform(X_val)\n",
    "        \n",
    "        # Codificar etiquetas\n",
    "        y_train_encoded = self.label_encoder.fit_transform(y_train)\n",
    "        y_val_encoded = self.label_encoder.transform(y_val)\n",
    "        \n",
    "        # Crear modelo\n",
    "        num_classes = len(np.unique(y_train))\n",
    "        input_shape = X_train_scaled.shape[1]\n",
    "        \n",
    "        if self.model_type == 'neural_network':\n",
    "            self.model = self.create_neural_network(input_shape, num_classes)\n",
    "        elif self.model_type == 'cnn':\n",
    "            self.model = self.create_cnn_model(input_shape, num_classes)\n",
    "        \n",
    "        # Callbacks para entrenamiento\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "        ]\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        history = self.model.fit(\n",
    "            X_train_scaled, y_train_encoded,\n",
    "            validation_data=(X_val_scaled, y_val_encoded),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Realiza predicciones sobre nuevos datos\n",
    "        \"\"\"\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        predictions = self.model.predict(X_test_scaled)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        predicted_emotions = self.label_encoder.inverse_transform(predicted_classes)\n",
    "        \n",
    "        return predicted_emotions, predictions\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evalúa el rendimiento del modelo\n",
    "        \"\"\"\n",
    "        y_pred, probabilities = self.predict(X_test)\n",
    "        \n",
    "        # Métricas de evaluación\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        return accuracy, report, conf_matrix\n",
    "```\n",
    "\n",
    "## 7. Entrenamiento y Evaluación del Modelo\n",
    "\n",
    "```python\n",
    "# Ejemplo de uso del clasificador\n",
    "def train_emotion_classifier(features, emotions):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa el clasificador de emociones\n",
    "    \"\"\"\n",
    "    # Dividir datos en entrenamiento, validación y prueba\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        features, emotions, test_size=0.4, random_state=42, stratify=emotions\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    print(f\"Datos de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "    print(f\"Datos de validación: {X_val.shape[0]} muestras\")\n",
    "    print(f\"Datos de prueba: {X_test.shape[0]} muestras\")\n",
    "    \n",
    "    # Crear y entrenar clasificador\n",
    "    classifier = EmotionClassifier(model_type='neural_network')\n",
    "    history = classifier.train(X_train, y_train, X_val, y_val, epochs=50)\n",
    "    \n",
    "    # Evaluar modelo\n",
    "    accuracy, report, conf_matrix = classifier.evaluate(X_test, y_test)\n",
    "    \n",
    "    print(f\"\\nPrecisión del modelo: {accuracy:.4f}\")\n",
    "    print(f\"\\nReporte de clasificación:\\n{report}\")\n",
    "    \n",
    "    # Visualizar resultados\n",
    "    plot_training_history(history)\n",
    "    plot_confusion_matrix(conf_matrix, classifier.label_encoder.classes_)\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Visualiza la historia de entrenamiento\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validación')\n",
    "    plt.title('Precisión del Modelo')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Precisión')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "    plt.plot(history.history['val_loss'], label='Validación')\n",
    "    plt.title('Pérdida del Modelo')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix, class_names):\n",
    "    \"\"\"\n",
    "    Visualiza la matriz de confusión\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Matriz de Confusión')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Valor Real')\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "## 8. Predicción en Tiempo Real\n",
    "\n",
    "```python\n",
    "def real_time_emotion_prediction(model_path, audio_file_path):\n",
    "    \"\"\"\n",
    "    Realiza predicción de emoción en tiempo real para un archivo de audio\n",
    "    \"\"\"\n",
    "    # Cargar modelo entrenado\n",
    "    classifier = EmotionClassifier()\n",
    "    # classifier.model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Procesar archivo de audio\n",
    "    audio, sr = load_audio_file(audio_file_path)\n",
    "    if audio is None:\n",
    "        return \"Error al cargar el archivo de audio\"\n",
    "    \n",
    "    # Preprocesar y extraer características\n",
    "    audio_processed = preprocess_audio(audio, sr)\n",
    "    features = extract_features(audio_processed, sr)\n",
    "    \n",
    "    # Realizar predicción\n",
    "    features_reshaped = features.reshape(1, -1)\n",
    "    emotion, probabilities = classifier.predict(features_reshaped)\n",
    "    \n",
    "    return emotion[0], probabilities[0]\n",
    "\n",
    "def visualize_audio_waveform(audio_file_path):\n",
    "    \"\"\"\n",
    "    Visualiza la forma de onda y espectrograma de un archivo de audio\n",
    "    \"\"\"\n",
    "    audio, sr = load_audio_file(audio_file_path)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Forma de onda\n",
    "    plt.subplot(3, 1, 1)\n",
    "    time = np.linspace(0, len(audio)/sr, len(audio))\n",
    "    plt.plot(time, audio)\n",
    "    plt.title('Forma de Onda del Audio')\n",
    "    plt.xlabel('Tiempo (s)')\n",
    "    plt.ylabel('Amplitud')\n",
    "    \n",
    "    # Espectrograma\n",
    "    plt.subplot(3, 1, 2)\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Espectrograma')\n",
    "    \n",
    "    # MFCC\n",
    "    plt.subplot(3, 1, 3)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title('Coeficientes MFCC')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "## 9. Ejemplo de Uso Completo\n",
    "\n",
    "```python\n",
    "# Ejemplo de uso completo del sistema\n",
    "def main_emotion_analysis():\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta todo el pipeline de análisis de emociones\n",
    "    \"\"\"\n",
    "    print(\"=== Analizador de Emociones por Voz ===\\n\")\n",
    "    \n",
    "    # 1. Preparar dataset (reemplazar con tu directorio de datos)\n",
    "    # audio_directory = \"path/to/your/audio/dataset\"\n",
    "    # features, emotions = prepare_dataset(audio_directory, emotions_mapping)\n",
    "    \n",
    "    # Para demostración, crear datos sintéticos\n",
    "    np.random.seed(42)\n",
    "    num_samples = 1000\n",
    "    num_features = 50\n",
    "    features = np.random.randn(num_samples, num_features)\n",
    "    emotions = np.random.choice(['Felicidad', 'Tristeza', 'Enojo', 'Miedo', 'Neutral'], \n",
    "                               size=num_samples)\n",
    "    \n",
    "    print(f\"Dataset cargado: {features.shape[0]} muestras con {features.shape[1]} características\")\n",
    "    \n",
    "    # 2. Explorar datos\n",
    "    features_df = pd.DataFrame(features, columns=[f'feature_{i}' for i in range(features.shape[1])])\n",
    "    # visualize_audio_features(features_df, emotions)\n",
    "    \n",
    "    # 3. Entrenar modelo\n",
    "    classifier = train_emotion_classifier(features, emotions)\n",
    "    \n",
    "    # 4. Ejemplo de predicción en tiempo real\n",
    "    # audio_file = \"path/to/test/audio.wav\"\n",
    "    # emotion, confidence = real_time_emotion_prediction(classifier, audio_file)\n",
    "    # print(f\"Emoción detectada: {emotion} (Confianza: {np.max(confidence):.2f})\")\n",
    "    \n",
    "    print(\"\\n=== Análisis Completado ===\")\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "# Ejecutar análisis principal\n",
    "if __name__ == \"__main__\":\n",
    "    classifier = main_emotion_analysis()\n",
    "```\n",
    "\n",
    "## 10. Utilidades Adicionales\n",
    "\n",
    "```python\n",
    "def save_model(classifier, model_path, scaler_path, encoder_path):\n",
    "    \"\"\"\n",
    "    Guarda el modelo entrenado y los preprocessors\n",
    "    \"\"\"\n",
    "    classifier.model.save(model_path)\n",
    "    \n",
    "    import joblib\n",
    "    joblib.dump(classifier.scaler, scaler_path)\n",
    "    joblib.dump(classifier.label_encoder, encoder_path)\n",
    "    \n",
    "    print(f\"Modelo guardado en: {model_path}\")\n",
    "    print(f\"Scaler guardado en: {scaler_path}\")\n",
    "    print(f\"Encoder guardado en: {encoder_path}\")\n",
    "\n",
    "def load_trained_model(model_path, scaler_path, encoder_path):\n",
    "    \"\"\"\n",
    "    Carga un modelo previamente entrenado\n",
    "    \"\"\"\n",
    "    import joblib\n",
    "    \n",
    "    classifier = EmotionClassifier()\n",
    "    classifier.model = tf.keras.models.load_model(model_path)\n",
    "    classifier.scaler = joblib.load(scaler_path)\n",
    "    classifier.label_encoder = joblib.load(encoder_path)\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "def batch_emotion_analysis(audio_directory, classifier):\n",
    "    \"\"\"\n",
    "    Analiza múltiples archivos de audio en lote\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    import os\n",
    "    for audio_file in os.listdir(audio_directory):\n",
    "        if audio_file.endswith(('.wav', '.mp3', '.m4a')):\n",
    "            file_path = os.path.join(audio_directory, audio_file)\n",
    "            \n",
    "            try:\n",
    "                emotion, confidence = real_time_emotion_prediction(classifier, file_path)\n",
    "                results.append({\n",
    "                    'archivo': audio_file,\n",
    "                    'emocion': emotion,\n",
    "                    'confianza': np.max(confidence)\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando {audio_file}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "```\n",
    "\n",
    "Este notebook proporciona un sistema completo para análisis de emociones por voz usando inteligencia artificial, incluyendo:\n",
    "\n",
    "- Preprocesamiento de audio\n",
    "- Extracción de características acústicas\n",
    "- Modelos de deep learning\n",
    "- Evaluación y visualización\n",
    "- Predicción en tiempo real\n",
    "- Utilidades para guardar/cargar modelos\n",
    "\n",
    "Para usar este código, necesitarás un dataset de audio etiquetado con emociones organizizado en carpetas por cada emoción."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
